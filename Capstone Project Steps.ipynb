{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Student Arrivals Data Model\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "I choose to work with the Udacity provided project, hence I select the immigration and US cities demographics datasets as well as along with 2 additional ones: Airlines and Visa types. The objective is to build a dimensional model in Amazon Redshift in order to analyze the data of immigrants with student visas and fill it with an ETL process.\n",
    "\n",
    "The project follows the following steps:\n",
    "* Step 1: Project Scope and data gathering\n",
    "* Step 2: Exploring, Assessing and saving the Data\n",
    "* Step 3: Defining the Data Model\n",
    "* Step 4: Running the ETL\n",
    "* Step 5: Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "import configparser\n",
    "import os\n",
    "from pyspark.sql.functions import isnan, when, count, col, expr, year, month, date_format\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <span style=\"color:blue\">Step 1: Project Scope and data gathering</span>\n",
    "\n",
    "#### 1.1 Scope\n",
    "For this project, two of the four datasets provided are used: *I94 Immigration Data* and *U.S. City Demographic Data*, also two extra datasets: *iataCodes.xlsx* and *visaType.csv*.\n",
    "\n",
    "A subset of the immigration data is used - student visa records only(I94VISA = 3). The end solution is a dimensional model built in Redshift to analyze and make reports about student data. For instance, discovering insights about student US State preference, student nationalities that visit the country the most, student arrivals per month, etc.\n",
    "\n",
    "The datasets are preprocessed using Spark and Pandas in the Udacity Workspace with a Jupyter notebook and then saved to S3 in parquet files, then with an ETL process written in python, the staging, dimension and fact tables are created in Redshift and filled with the data stored in S3.\n",
    "\n",
    "#### 1.2 Data Sources description \n",
    "\n",
    "- **I94 Immigration Data**: This data comes from the US National Tourism and Trade Office. [source](https://travel.trade.gov/research/reports/i94/historical/2016.html).\n",
    "Contains international visitor arrival statistics by world regions and select countries, type of visa, mode of transportation, age groups, states visited (first intended address only), and the top ports of entry (for select countries), etc.\n",
    "- **U.S. City Demographic Data**: This data comes from OpenSoft. [source](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n",
    "Contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000. This data comes from the US Census Bureau's 2015 American Community Survey.\n",
    "- **iataCodes.xlsx**: This data was gathered from a few sources:\n",
    "[source1](https://www.iata.org/en/publications/directories/code-search/),\n",
    "[source2](https://azcargo.cz/en/services/support/iata-airline-codes/)\n",
    "[source3](https://en.wikipedia.org/wiki/List_of_airline_codes)\n",
    "Contains the Airline codes and Airline names.\n",
    "- **visaType.csv**: This data comes from the US National Tourism and Trade Office.\n",
    "[source](https://www.trade.gov/i-94-arrivals-program)\n",
    "Contains the Visa codes and Visa descriptions.  \n",
    "- **I94_SAS_Labels_Descriptions.SAS**: This data was provided by Udacity.\n",
    "Contains a short description for each column of the I94 Immigration Dataset. *State, Country, Entry mode and Port catalogs* are extracted from this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Loading Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_catalog(file, idx):\n",
    "    \"\"\"Reads the content of I94_SAS_Labels_Descriptions.SAS file and returns a pandas data frame\n",
    "       with the corresponding labels according to the \"value\"\n",
    "\n",
    "       Input Arguments: file - file content, \n",
    "                        idx - value items, example: i94addrl,i94cntyl\n",
    "    \"\"\"\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    df = pd.DataFrame.from_dict(dic, orient=\"index\").reset_index()\n",
    "    df.columns = [\"code\",\"desc\"]\n",
    "    return df\n",
    "\n",
    "# opens the file\n",
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Loading Country Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code     int16\n",
      "desc    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                                               desc\n",
       "0   582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1   236                                        AFGHANISTAN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country = get_catalog(f_content, \"i94cntyl\")\n",
    "\n",
    "df_country.loc[len(df_country.index)] = ['99', 'All Other Codes']\n",
    "df_country['code'] = df_country['code'].astype('int16')\n",
    "\n",
    "print(df_country.dtypes)\n",
    "df_country.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Loading mode Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code     int16\n",
      "desc    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code desc\n",
       "0     1  Air\n",
       "1     2  Sea"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode = get_catalog(f_content, \"i94mode\")\n",
    "\n",
    "df_mode.loc[len(df_mode.index)] = ['-1', 'No info']\n",
    "df_mode['code'] = df_mode['code'].astype('int16')\n",
    "\n",
    "print(df_mode.dtypes)\n",
    "df_mode.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Loading Port Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code    object\n",
      "desc    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE, AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code           desc\n",
       "0  ALC      ALCAN, AK\n",
       "1  ANC  ANCHORAGE, AK"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port = get_catalog(f_content, \"$i94prtl\")\n",
    "\n",
    "df_port.loc[len(df_port.index)] = ['-1', 'No info']\n",
    "\n",
    "print(df_port.dtypes)\n",
    "df_port.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Loading State Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code    object\n",
      "desc    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code     desc\n",
       "0   AL  ALABAMA\n",
       "1   AK   ALASKA"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_addr = get_catalog(f_content, \"i94addrl\")\n",
    "\n",
    "print(df_addr.dtypes)\n",
    "df_addr.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Loading \"Main\" table (student visa only!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reading configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('aws/credentials.cfg'))\n",
    "output_data = config['AWS']['S3_BUCKET']\n",
    "\n",
    "# Building a spark session with a connection to AWS S3\n",
    "spark = SparkSession.builder \\\n",
    "        .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11,org.apache.hadoop:hadoop-aws:2.7.2\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\",config['AWS']['AWS_ACCESS_KEY_ID']) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\",config['AWS']['AWS_SECRET_ACCESS_KEY']) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# months and fields to load\n",
    "month_list = [\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
    "field_list = ['cicid', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', \n",
    "              'depdate', 'i94bir', 'entdepa', 'entdepd', 'entdepu', 'matflag', \n",
    "              'biryear', 'dtaddto', 'gender', 'airline', 'fltno', 'visatype']\n",
    "\n",
    "for month in month_list:\n",
    "    fname = f'../../data/18-83510-I94-Data-2016/i94_{month}16_sub.sas7bdat'\n",
    "    # student visa only!\n",
    "    df_t = spark.read.format('com.github.saurfang.sas.spark').load(fname)\n",
    "    df_t = df_t.filter(df_t.i94visa == 3.0).select(field_list)\n",
    "   \n",
    "    if month == 'jan':\n",
    "        df_final = df_t\n",
    "    else:\n",
    "        df_final = df_final.union(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows loaded: 1573271\n",
      "CPU times: user 60.7 ms, sys: 7.41 ms, total: 68.1 ms\n",
      "Wall time: 7min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_final = df_final.cache()\n",
    "print(f\"Number of rows loaded: {df_final.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "|cicid|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender|airline|fltno|visatype|\n",
      "+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "|  7.0| 101.0| 101.0|    BOS|20465.0|    1.0|     MA|   null|  20.0|      T|   null|   null|   null| 1996.0|    D/S|     M|     LH|  424|      F1|\n",
      "|  8.0| 101.0| 101.0|    BOS|20465.0|    1.0|     MA|   null|  20.0|      T|   null|   null|   null| 1996.0|    D/S|     M|     LH|  424|      F1|\n",
      "+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Loading extra data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Loading *us-cities-demographics.csv* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City                       object\n",
      "State                      object\n",
      "Median Age                float64\n",
      "Male Population           float64\n",
      "Female Population         float64\n",
      "Total Population            int64\n",
      "Number of Veterans        float64\n",
      "Foreign-born              float64\n",
      "Average Household Size    float64\n",
      "State Code                 object\n",
      "Race                       object\n",
      "Count                       int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = './data/us-cities-demographics.csv'\n",
    "df_demo = pd.read_csv(fname, sep=';')\n",
    "\n",
    "print(df_demo.dtypes)\n",
    "df_demo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Loading *visaType.csv* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visa_code    object\n",
      "visa_desc    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visa_code</th>\n",
       "      <th>visa_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>Visa Holder: Non-immigrant student and exchang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F2</td>\n",
       "      <td>Visa Holder: Spouse or Child of Academic Student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  visa_code                                          visa_desc\n",
       "0        F1  Visa Holder: Non-immigrant student and exchang...\n",
       "1        F2   Visa Holder: Spouse or Child of Academic Student"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = './data/visaType.csv'\n",
    "df_visa = pd.read_csv(fname, sep=';')\n",
    "\n",
    "print(df_visa.dtypes)\n",
    "df_visa.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Loading *iataCodes.xlsx* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iata_code        object\n",
      "iata_airlines    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iata_code</th>\n",
       "      <th>iata_airlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2G</td>\n",
       "      <td>CargoItalia (alternate)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iata_code            iata_airlines\n",
       "0        AA        American Airlines\n",
       "1        2G  CargoItalia (alternate)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = './data/iataCodes.xlsx'\n",
    "df_airline = pd.read_excel(fname, converters={'iata_code':str,'iata_airlines':str})\n",
    "\n",
    "print(df_airline.dtypes)\n",
    "df_airline.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <span style=\"color:blue\">Step 2: Exploring, Assessing and saving the Data</span>\n",
    "#### 2.1 Exploring the Data \n",
    "Data is explored and cleaned using data wrangling functions and methods like `printSchema()`, `isNull()`, `isnan()`, `groupby()`, `filter()`, `count()`, etc.\n",
    "\n",
    "#### 2.2 Cleaning Steps\n",
    "\n",
    "For I94 Immigration Data:\n",
    "- Checking duplicates: duplicated records were deleted (cicid must be unique).\n",
    "- Checking missing values: missing vales were replaced by default values (-1:no data, 99: all other values, 0, or '').\n",
    "- Casting: several fields were casted from Double to Integer\n",
    "- Checking non existing codes: codes that don't exist in the Catalogs were replaced by default values.\n",
    "\n",
    "For us-cities-demographics:\n",
    "- Was pivoted to have ethnicity data in columns.\n",
    "- Was aggregated by State.\n",
    "\n",
    "#### 2.3 Saving data to S3 in parquet files\n",
    "<img src=\"./s3.JPG\" width=\"300\" height=\"300\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Exploring and Cleaning the \"Main table\" (I94 Immigration Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1573271\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Number of rows loaded: 1,573,271\n",
    "print(df_final.count())\n",
    "df_final.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Checking duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cicid duplicated: 125296\n",
      "Total rows Duplicated: 256947\n"
     ]
    }
   ],
   "source": [
    "# number of cicid duplicated\n",
    "print(f\"cicid duplicated: {df_final.groupby('cicid').count().filter(col('count')>1).count()}\")\n",
    "\n",
    "# total rows to drop\n",
    "rows_dup = df_final.groupby('cicid').count().filter(col('count')>1).agg({'count':'sum'}).collect()[0]['sum(count)']\n",
    "print(f\"Total rows Duplicated: {rows_dup}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after dropping duplicated rows: 1316324\n",
      "Percentage of duplicated rows dropped: 16.33%\n"
     ]
    }
   ],
   "source": [
    "# number of rows and after dropping\n",
    "print(f\"Number of rows after dropping duplicated rows: {1573271 - rows_dup}\")\n",
    "print(f\"Percentage of duplicated rows dropped: {round(rows_dup/1573271 * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|  cicid|count|\n",
      "+-------+-----+\n",
      "|17267.0|    2|\n",
      "|21911.0|    2|\n",
      "+-------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifying and saving the duplicated rows\n",
    "df_final_dup = df_final.groupby('cicid').count().filter(col('count')>1)\n",
    "df_final_dup.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1316324"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping duplicates\n",
    "df_final2 = df_final.join(df_final_dup, on=['cicid'], how='left_anti')\n",
    "df_final2 = df_final2.cache()\n",
    "\n",
    "#rows after dropping duplicates\n",
    "df_final2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "|cicid|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender|airline|fltno|visatype|\n",
      "+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "|    0|  1399|     0|      0|      0|   1001|  41128| 866828|    28|     23| 867670|1310466| 866746|     28|   1424|  1120|  43504| 2331|       0|\n",
      "+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final2.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_final.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Replacing missing values\n",
    "df_final2 = df_final2.fillna({'i94cit':-1, 'i94mode':-1, 'i94addr':'99', 'depdate':0, 'i94bir':0, 'entdepa':'', 'entdepd':'',\n",
    "                              'entdepu':'', 'matflag':'', 'biryear':0, 'dtaddto':'', 'gender':'', 'airline': '-1', 'fltno': '-1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "|cicid|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender|airline|fltno|visatype|\n",
      "+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "|    0|     0|     0|      0|      0|      0|      0|      0|     0|      0|      0|      0|      0|      0|      0|     0|      0|    0|       0|\n",
      "+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final2.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_final.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+-------+----------+-------+-------+----------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "|cicid|i94cit|i94res|i94port|   arrdate|i94mode|i94addr|   depdate|i94bir|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender|airline|fltno|visatype|\n",
      "+-----+------+------+-------+----------+-------+-------+----------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "|  299|   103|   103|    BOS|2016-01-30|      1|     RI|1960-01-01|    25|      T|       |       |       |   1991|    D/S|     M|     LX|   52|      F1|\n",
      "|  305|   103|   103|    FTL|2016-01-04|      1|     FL|1960-01-01|    24|      T|       |       |       |   1992|    D/S|     M|     BW|  480|      F1|\n",
      "+-----+------+------+-------+----------+-------+-------+----------+------+-------+-------+-------+-------+-------+-------+------+-------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# casting these columns from double to integer\n",
    "cast_lst = ['cicid','i94cit','i94res','arrdate','i94mode','depdate','i94bir','biryear']\n",
    "\n",
    "for col_name in cast_lst:\n",
    "    df_final2 = df_final2.withColumn(col_name, col(col_name).cast('int'))\n",
    "                         \n",
    "# convert arrdate and depdate from double to date   \n",
    "df_final2 = df_final2.withColumn('arrdate',expr(\"date_add('1960-01-01',arrdate)\")) \\\n",
    "                     .withColumn('depdate',expr(\"date_add('1960-01-01',depdate)\"))\n",
    "    \n",
    "df_final2.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Exploring and Cleaning the \"Catalogs\" codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### \"Country\" Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_df_cntry = df_final2.select('i94cit').dropDuplicates().withColumnRenamed(\"i94cit\",\"code\").toPandas()\n",
    "pd_df_cntry2 = df_final2.select('i94res').dropDuplicates().withColumnRenamed(\"i94res\",\"code\").toPandas()\n",
    "\n",
    "pd_df_cntryf = pd.concat([pd_df_cntry,pd_df_cntry2], join='outer').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of codes that don't exist in the country catalog: 29\n"
     ]
    }
   ],
   "source": [
    "# number of codes that don't exist in the country catalog\n",
    "df_tmp = set(pd_df_cntryf.code) - set(df_country.code)\n",
    "print(f\" Number of codes that don't exist in the country catalog: {len(df_tmp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# setting to 99 the codes that don't exist in the country catalog\n",
    "df_final2 = df_final2.withColumn('i94cit', when(df_final2.i94cit.isin(df_tmp), 99).otherwise(df_final2.i94cit)) \\\n",
    "                     .withColumn('i94res', when(df_final2.i94res.isin(df_tmp), 99).otherwise(df_final2.i94res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### \"Mode\" Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_df_mode = df_final2.select('i94mode').dropDuplicates().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of codes that don't exist in the mode catalog: 1\n"
     ]
    }
   ],
   "source": [
    "# number of codes that don't exist in the mode catalog\n",
    "df_tmp = set(pd_df_mode.i94mode) - set(df_mode.code)\n",
    "print(f\" Number of codes that don't exist in the mode catalog: {len(df_tmp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# setting to -1 the codes that don't exist in the mode catalog\n",
    "df_final2 = df_final2.withColumn('i94mode', when(df_final2.i94mode == 0,-1).otherwise(df_final2.i94mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### \"Port\" Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_df_port = df_final2.select('i94port').dropDuplicates().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of codes that don't exist in the port catalog: 0\n"
     ]
    }
   ],
   "source": [
    "# number of codes that don't exist in the port catalog\n",
    "df_tmp = set(pd_df_port.i94port) - set(df_port.code)\n",
    "print(f\" Number of codes that don't exist in the port catalog: {len(df_tmp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### \"State\" Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_df_state = df_final2.select('i94addr').dropDuplicates().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of codes that don't exist in the state catalog: 27\n"
     ]
    }
   ],
   "source": [
    "# number of codes that don't exist in the state catalog\n",
    "df_tmp = set(pd_df_state.i94addr) - set(df_addr.code)\n",
    "print(f\" Number of codes that don't exist in the state catalog: {len(df_tmp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# setting to 99 the codes that don't exist in the state catalog\n",
    "df_final2 = df_final2.withColumn('i94addr', when(df_final2.i94addr.isin(df_tmp), '99').otherwise(df_final2.i94addr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### \"Visa\" Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_df_visa = df_final2.select('visatype').dropDuplicates().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of codes that don't exist in the visa catalog: 0\n"
     ]
    }
   ],
   "source": [
    "# number of codes that don't exist in the visa catalog\n",
    "df_tmp = set(pd_df_visa.visatype) - set(df_visa.visa_code)\n",
    "print(f\" Number of codes that don't exist in the visa catalog: {len(df_tmp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### \"Airline\" Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd_df_airline = df_final2.select('airline').dropDuplicates().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of codes that don't exist in the airline catalog: 229\n"
     ]
    }
   ],
   "source": [
    "# number of codes that don't exist in the airline catalog\n",
    "df_tmp = set(pd_df_airline.airline) - set(df_airline.iata_code)\n",
    "print(f\" Number of codes that don't exist in the airline catalog: {len(df_tmp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# setting to 99 the codes that don't exist in the airline catalog\n",
    "df_final2 = df_final2.withColumn('airline', when(df_final2.airline.isin(df_tmp), '99').otherwise(df_final2.airline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Exploring and cleaning: *us-cities-demographics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demot = df_demo.drop(columns = ['Race','Count']).drop_duplicates()\n",
    "len(df_demot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demo_piv = df_demo[['State Code','City','Race','Count']]\n",
    "#pivot(index=['City','State'], columns='Race', values='Count')\n",
    "\n",
    "df_demo_piv = (df_demo.set_index([\"State Code\", \"City\"])\n",
    "                      .pivot(columns=\"Race\")['Count']\n",
    "                      .reset_index()\n",
    "                      .rename_axis(None, axis=1)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596\n"
     ]
    }
   ],
   "source": [
    "df_demof = df_demot.merge(df_demo_piv, how='inner', on=['State Code','City'])\n",
    "print(len(df_demof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black or African-American</th>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>8841.0</td>\n",
       "      <td>21330.0</td>\n",
       "      <td>25924.0</td>\n",
       "      <td>37756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>351.0</td>\n",
       "      <td>30473.0</td>\n",
       "      <td>3917.0</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>58723.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "\n",
       "   Average Household Size State Code  American Indian and Alaska Native  \\\n",
       "0                    2.60         MD                             1084.0   \n",
       "1                    2.39         MA                              351.0   \n",
       "\n",
       "     Asian  Black or African-American  Hispanic or Latino    White  \n",
       "0   8841.0                    21330.0             25924.0  37756.0  \n",
       "1  30473.0                     3917.0              2566.0  58723.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demof.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demof = df_demof.drop(columns = ['City','State'])\n",
    "\n",
    "#changing column names\n",
    "df_demof = df_demof.groupby('State Code').agg({'Median Age':'median', \n",
    "                                                'Male Population':'sum', \n",
    "                                                'Female Population':'sum', \n",
    "                                                'Total Population':'sum', \n",
    "                                                'Number of Veterans':'sum',\n",
    "                                                'Foreign-born':'sum',\n",
    "                                                'Average Household Size':'mean',\n",
    "                                                'American Indian and Alaska Native':'sum',\n",
    "                                                'Black or African-American':'sum',\n",
    "                                                'Hispanic or Latino':'sum',\n",
    "                                                'White':'sum',\n",
    "                                                'Asian':'sum'                                  \n",
    "                                               })\n",
    "# formatting column names\n",
    "df_demof.reset_index(level=0, inplace=True)\n",
    "df_demof.rename(columns=lambda x: x.replace(\" \", \"_\"), inplace=True)\n",
    "df_demof.rename(columns=lambda x: x.replace(\"-\", \"_\"), inplace=True)\n",
    "df_demof.rename(columns=str.lower, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>american_indian_and_alaska_native</th>\n",
       "      <th>black_or_african_american</th>\n",
       "      <th>hispanic_or_latino</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>32.2</td>\n",
       "      <td>152945.0</td>\n",
       "      <td>145750.0</td>\n",
       "      <td>298695</td>\n",
       "      <td>27492.0</td>\n",
       "      <td>33258.0</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>36339.0</td>\n",
       "      <td>23107.0</td>\n",
       "      <td>27261.0</td>\n",
       "      <td>212696.0</td>\n",
       "      <td>36825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>38.0</td>\n",
       "      <td>497248.0</td>\n",
       "      <td>552381.0</td>\n",
       "      <td>1049629</td>\n",
       "      <td>71543.0</td>\n",
       "      <td>52154.0</td>\n",
       "      <td>2.434286</td>\n",
       "      <td>8084.0</td>\n",
       "      <td>521068.0</td>\n",
       "      <td>39313.0</td>\n",
       "      <td>498920.0</td>\n",
       "      <td>28769.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  median_age  male_population  female_population  \\\n",
       "0         AK        32.2         152945.0           145750.0   \n",
       "1         AL        38.0         497248.0           552381.0   \n",
       "\n",
       "   total_population  number_of_veterans  foreign_born  average_household_size  \\\n",
       "0            298695             27492.0       33258.0                2.770000   \n",
       "1           1049629             71543.0       52154.0                2.434286   \n",
       "\n",
       "   american_indian_and_alaska_native  black_or_african_american  \\\n",
       "0                            36339.0                    23107.0   \n",
       "1                             8084.0                   521068.0   \n",
       "\n",
       "   hispanic_or_latino     white    asian  \n",
       "0             27261.0  212696.0  36825.0  \n",
       "1             39313.0  498920.0  28769.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_demof))\n",
    "df_demof.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Saving all data sets in S3 (as parquet files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Loading the main table to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Loading data to s3a://jorge-udacity-bucket2/I94-Data... ####\n",
      "CPU times: user 8.19 ms, sys: 0 ns, total: 8.19 ms\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#write to parquet\n",
    "print(f\"#### Loading data to {output_data}I94-Data... ####\")\n",
    "\n",
    "# reducing from 200 partitions to 2, to reduce the loading time to s3\n",
    "df_final2 = df_final2.coalesce(2)\n",
    "df_final2.write.parquet(f\"{output_data}I94-Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = false)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- entdepa: string (nullable = false)\n",
      " |-- entdepd: string (nullable = false)\n",
      " |-- entdepu: string (nullable = false)\n",
      " |-- matflag: string (nullable = false)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- airline: string (nullable = false)\n",
      " |-- fltno: string (nullable = false)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Converting data frames from pandas to spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sqlCtx = SQLContext(sc)\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"code\", IntegerType(), True), \\\n",
    "    StructField(\"desc\",StringType(),True) \\\n",
    "  ])\n",
    "\n",
    "# converting pandas df to spark df\n",
    "dfs_demof = sqlCtx.createDataFrame(df_demof)\n",
    "dfs_airline = sqlCtx.createDataFrame(df_airline)\n",
    "dfs_visa = sqlCtx.createDataFrame(df_visa)\n",
    "dfs_addr = sqlCtx.createDataFrame(df_addr)\n",
    "dfs_port = sqlCtx.createDataFrame(df_port)\n",
    "dfs_mode = sqlCtx.createDataFrame(df_mode, schema=schema)\n",
    "dfs_country = sqlCtx.createDataFrame(df_country, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- male_population: double (nullable = true)\n",
      " |-- female_population: double (nullable = true)\n",
      " |-- total_population: long (nullable = true)\n",
      " |-- number_of_veterans: double (nullable = true)\n",
      " |-- foreign_born: double (nullable = true)\n",
      " |-- average_household_size: double (nullable = true)\n",
      " |-- american_indian_and_alaska_native: double (nullable = true)\n",
      " |-- black_or_african_american: double (nullable = true)\n",
      " |-- hispanic_or_latino: double (nullable = true)\n",
      " |-- white: double (nullable = true)\n",
      " |-- asian: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_demof.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- iata_airlines: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_airline.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- visa_code: string (nullable = true)\n",
      " |-- visa_desc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_visa.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_addr.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_port.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: integer (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_mode.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: integer (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_country.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Saving metadata to a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>desc_column</th>\n",
       "      <th>expected_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dim_country</td>\n",
       "      <td>description</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dim_entry_mode</td>\n",
       "      <td>description</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dim_visa_type</td>\n",
       "      <td>description</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dim_entry_port</td>\n",
       "      <td>description</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dim_airline</td>\n",
       "      <td>description</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dim_date</td>\n",
       "      <td></td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dim_destination_state</td>\n",
       "      <td>state_name</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>student_arrivals_fact</td>\n",
       "      <td></td>\n",
       "      <td>1316324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   table  desc_column  expected_rows\n",
       "0            dim_country  description            290\n",
       "1         dim_entry_mode  description              5\n",
       "2          dim_visa_type  description             20\n",
       "3         dim_entry_port  description            661\n",
       "4            dim_airline  description            197\n",
       "5               dim_date                         366\n",
       "6  dim_destination_state   state_name             55\n",
       "7  student_arrivals_fact                     1316324"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data = {}\n",
    "\n",
    "meta_data['table'] = [\"dim_country\", \"dim_entry_mode\", \"dim_visa_type\", \"dim_entry_port\",\n",
    "                      \"dim_airline\", \"dim_date\", \"dim_destination_state\", \"student_arrivals_fact\"]\n",
    "\n",
    "meta_data['desc_column'] = [\"description\", \"description\", \"description\", \"description\", \n",
    "                            \"description\", \"\", \"state_name\", \"\"]\n",
    "\n",
    "arrdate_count = df_final2.select('arrdate').dropDuplicates().count()\n",
    "\n",
    "meta_data['expected_rows'] = [len(df_country), len(df_mode), len(df_visa), len(df_port),\n",
    "                              len(df_airline), arrdate_count, len(df_addr), df_final2.count()]\n",
    "\n",
    "df_meta_data = pd.DataFrame.from_dict(meta_data)\n",
    "df_meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### saving metadata file ####\n"
     ]
    }
   ],
   "source": [
    "print(f\"#### saving metadata file ####\")\n",
    "df_meta_data.to_json(\"./metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Loading Catalogs and extra data sets to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Loading Catalogs and extra data sets to S3... ####\n",
      "CPU times: user 13.8 ms, sys: 189 s, total: 13.9 ms\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"#### Loading Catalogs and extra data sets to S3... ####\")\n",
    "\n",
    "dfs_demof.write.parquet(f\"{output_data}demographics\")\n",
    "dfs_airline.write.parquet(f\"{output_data}airlines\")\n",
    "dfs_visa.write.parquet(f\"{output_data}visas\")\n",
    "dfs_addr.write.parquet(f\"{output_data}states\")\n",
    "dfs_port.write.parquet(f\"{output_data}port\")\n",
    "dfs_mode.write.parquet(f\"{output_data}mode\")\n",
    "dfs_country.write.parquet(f\"{output_data}countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <span style=\"color:blue\">Step 3: Defining the Data Model</span>\n",
    "#### 3.1 Conceptual Data Model\n",
    "I chose a dimensional model in Redshift because I'm working with structured and relatively small amount of data(1.3 Millon rows). If data grows, It will not be a problem since a Redshift cluster is scalable, distributed, powerful and cost-effective. The datasets structures adaptnaturally to a dimensional model.\n",
    "\n",
    "The Data model has one fact table and 7 dimensional tables.\n",
    "\n",
    "1- Fact table - **student_arrivals_fact**: is filled with the *i94 immigration data*\n",
    "\n",
    "2- Dimensional tables\n",
    "- **dim_visa_type**: is filled with the *visaType.csv* dataset.\n",
    "- **dim_entry_port**: is filled with the data extracted from *I94_SAS_Labels_Descriptions.SAS*\n",
    "- **dim_airline**: is filled with the *iataCodes.xlsx* dataset\n",
    "- **dim_date**: is filled with the arrival_date field of *student_arrivals_fact* table.\n",
    "- **dim_country**: is filled with the data extracted from *I94_SAS_Labels_Descriptions.SAS*\n",
    "- **dim_entry_mode**: is filled with the data extracted from *I94_SAS_Labels_Descriptions.SAS*\n",
    "- **dim_destination_state**: is filled with the data extracted from *I94_SAS_Labels_Descriptions.SAS* and *us-cities-demographics.csv*\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "Steps necessary to pipeline the data into the data model:\n",
    "\n",
    "* Create the staging, dimensional and fact tables.(if model doesn't exist)\n",
    "* Truncate dimensional tables.(except dim_date)\n",
    "* Copy data from S3 to staging tables and to some dimensional tables.\n",
    "* Insert data from the staging tables to the rest dimensional tables.\n",
    "* Insert data from the staging tables to the fact table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Data Model**\n",
    "![](./Capstone_ER.jpeg)\n",
    "**Data Flow**\n",
    "![](./Data_Flow.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <span style=\"color:blue\">Step 4: Running the ETL</span>\n",
    "#### 4.1 Creating the data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* **Creating a Redshift Cluster(Optional):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Cluster Created!!! ####\n",
      "ec2.SecurityGroup(id='sg-072a9f5ed97106021')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n",
      "                 Key         Value\n",
      "0  ClusterIdentifier    dwhcluster\n",
      "1           NodeType     dc2.large\n",
      "2      ClusterStatus      creating\n",
      "3     MasterUsername       dwhuser\n",
      "4             DBName           dwh\n",
      "5              VpcId  vpc-646c301c\n",
      "6      NumberOfNodes             3\n"
     ]
    }
   ],
   "source": [
    "# Creates a redshift cluster, use the create argument\n",
    "!python ./src/create_redshift_cluster.py create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* **Wait until the cluster is available**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* **Creating tables: Staging, Facts and Dimensions (First time only)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Tables Dropped Correctly! ###\n",
      "### Tables Created Correctly! ###\n"
     ]
    }
   ],
   "source": [
    "# Drops all tables if exist and creates them\n",
    "!python ./src/create_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* **Extracting from S3, Transforming and Loading to Fact and Dimension tables in Redshift**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Executing query: TRUNCATE TABLE dim_country\n",
      "### Executing query: TRUNCATE TABLE dim_entry_mode\n",
      "### Executing query: TRUNCATE TABLE dim_visa_type\n",
      "### Executing query: TRUNCATE TABLE dim_entry_port\n",
      "### Executing query: TRUNCATE TABLE dim_airline\n",
      "### Executing query: TRUNCATE TABLE dim_destination_state\n",
      "### Executing query: TRUNCATE TABLE staging_i94\n",
      "### Executing query: TRUNCATE TABLE staging_demographics\n",
      "### Executing query: TRUNCATE TABLE staging_states\n",
      "### Tables truncated Correctly! ###\n",
      "### Executing query: COPY staging_i94 \n",
      "                       FROM 's3://jorge-udacity-bucket2/I94-Data/'\n",
      "                       IAM_ROLE 'arn:aws:iam::923772700788:role/myRedshiftRole'\n",
      "                       FORMAT AS PARQUET;\n",
      "                    \n",
      "### Executing query: COPY staging_demographics\n",
      "                        FROM 's3://jorge-udacity-bucket2/demographics/'\n",
      "                        IAM_ROLE 'arn:aws:iam::923772700788:role/myRedshiftRole'\n",
      "                        FORMAT AS PARQUET;\n",
      "                     \n",
      "### Executing query: COPY staging_states\n",
      "                          FROM 's3://jorge-udacity-bucket2/states/'\n",
      "                          IAM_ROLE 'arn:aws:iam::923772700788:role/myRedshiftRole'\n",
      "                          FORMAT AS PARQUET;\n",
      "                       \n",
      "### Executing query: COPY dim_country\n",
      "                           FROM 's3://jorge-udacity-bucket2/countries/'\n",
      "                           IAM_ROLE 'arn:aws:iam::923772700788:role/myRedshiftRole'\n",
      "                           FORMAT AS PARQUET;\n",
      "                        \n",
      "### Executing query: COPY dim_entry_mode\n",
      "                              FROM 's3://jorge-udacity-bucket2/mode/'\n",
      "                              IAM_ROLE 'arn:aws:iam::923772700788:role/myRedshiftRole'\n",
      "                              FORMAT AS PARQUET;\n",
      "                           \n",
      "### Executing query: COPY dim_visa_type\n",
      "                            FROM 's3://jorge-udacity-bucket2/visas/'\n",
      "                            IAM_ROLE 'arn:aws:iam::923772700788:role/myRedshiftRole'\n",
      "                            FORMAT AS PARQUET;\n",
      "                         \n",
      "### Executing query: COPY dim_entry_port\n",
      "                                 FROM 's3://jorge-udacity-bucket2/port/'\n",
      "                                 IAM_ROLE 'arn:aws:iam::923772700788:role/myRedshiftRole'\n",
      "                                 FORMAT AS PARQUET;\n",
      "                              \n",
      "### Executing query: COPY dim_airline\n",
      "                           FROM 's3://jorge-udacity-bucket2/airlines/'\n",
      "                           IAM_ROLE 'arn:aws:iam::923772700788:role/myRedshiftRole'\n",
      "                           FORMAT AS PARQUET;\n",
      "                        \n",
      "### Executing query: INSERT INTO dim_date (arrival_date, day, week, month, year, weekday)\n",
      "                        SELECT DISTINCT\n",
      "                               arrdate,\n",
      "                               EXTRACT(DAY FROM arrdate) AS day,\n",
      "                               EXTRACT(WEEK FROM arrdate) AS week,\n",
      "                               EXTRACT(MONTH FROM arrdate) AS month,\n",
      "                               EXTRACT(YEAR FROM arrdate) AS year,\n",
      "                               EXTRACT(DOW FROM arrdate) AS weekday\n",
      "                        FROM staging_i94\n",
      "                     \n",
      "### Executing query: INSERT INTO dim_destination_state (id_state, state_name, median_age, male_pop,\n",
      "                                                                        female_pop, veterans, foreign_born, avg_hh_size,\n",
      "                                                                        american_native, african_american, hispanic_latino, \n",
      "                                                                        white, asian)\n",
      "                                     SELECT s.code, s.description, d.median_age, d.male_population,\n",
      "                                            d.female_population, d.number_of_veterans, d.foreign_born, \n",
      "                                            d.average_household_size, d.american_indian_and_alaska_native, \n",
      "                                            d.black_or_african_american, d.hispanic_or_latino, d.white, d.asian\n",
      "                                     FROM staging_states s\n",
      "                                          LEFT JOIN staging_demographics d on (s.code = d.state_code)\n",
      "                                  \n",
      "### Executing query: INSERT INTO student_arrivals_fact (id_cic, id_citizenship, id_residency, id_visatype,\n",
      "                                                                       id_port, id_mode, id_state, id_airline, arrival_date,\n",
      "                                                                       flight_num, departure_date, admitted_date,\n",
      "                                                                       arrival_flag, departure_flag, update_flag,\n",
      "                                                                       match_flag, std_age, std_biryear, std_gender)\n",
      "                                    SELECT cicid, i94cit, i94res, visatype,\n",
      "                                           i94port, i94mode, i94addr, airline, arrdate,\n",
      "                                           fltno, depdate, dtaddto,\n",
      "                                           entdepa, entdepd, entdepu,\n",
      "                                           matflag, i94bir, biryear, gender\n",
      "                                    FROM staging_i94\n",
      "                                 \n",
      "### Loading Completed!! ###\n"
     ]
    }
   ],
   "source": [
    "!python ./src/etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Two quality checks are done:\n",
    "\n",
    "1- Counting records: The *medata.json* file is read, it contains the expected rows per table. The test compares the expected rows with the number of rows of each table.\n",
    "\n",
    "2- Identifying records with null or empty values in description column for dimensional tables.\n",
    " \n",
    "* **Running Quality Checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Data quality checking: counting records ####\n",
      "Passed: dim_country loaded with 290 rows, expected rows:290\n",
      "Passed: dim_entry_mode loaded with 5 rows, expected rows:5\n",
      "Error: Data quality check failed. dim_visa_type contained 0 rows\n",
      "Passed: dim_entry_port loaded with 661 rows, expected rows:661\n",
      "Passed: dim_airline loaded with 197 rows, expected rows:197\n",
      "Error: relation \"dim_date\" does not exist\n",
      "\n",
      "Passed: dim_destination_state loaded with 55 rows, expected rows:55\n",
      "Passed: student_arrivals_fact loaded with 1316324 rows, expected rows:1316324\n",
      "\n",
      "#### Data quality checking: identifying records with null or empty values in description column ####\n",
      "Passed: Data quality on table dim_country check passed with 0 NULL records\n",
      "Passed: Data quality on table dim_entry_mode check passed with 0 NULL records\n",
      "Passed: Data quality on table dim_visa_type check passed with 0 NULL records\n",
      "Passed: Data quality on table dim_entry_port check passed with 0 NULL records\n",
      "Error: Check failed. dim_airline contained 2 rows with NULL values in description\n",
      "No check needed for dim_date\n",
      "Passed: Data quality on table dim_destination_state check passed with 0 NULL records\n",
      "No check needed for student_arrivals_fact\n"
     ]
    }
   ],
   "source": [
    "#run quality checks\n",
    "!python ./src/data_quality.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* **Deleting a Redshift Cluster(Optional):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Cluster Deleted!!! ####\n"
     ]
    }
   ],
   "source": [
    "# Creates a redshift cluster, use the delete argument\n",
    "!python ./src/create_redshift_cluster.py delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "see the file: **data dictionary.xlsx**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# -------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### <span style=\"color:blue\">Step 5: Project Write Up</span>\n",
    "#### 5.1 Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "I preprocessed the data \"locally\" in the workspace since it was possible to do it, the amount of data processed is relatively small, it was not required to do it in the cloud. I processed the i94 immigration data using Spark because it is the largest dataset, it took half the time that in Pandas since Spark works with parallelism and partitions. I processed the rest of the data with Pandas. finally I saved all data in S3 to be easily consumed by Redshift.\n",
    "\n",
    "I chose Redshift since it is scalable, distributed, conventional(it uses SQL), powerful and cost-effective, and because the datasets structures adapt naturally to a dimensional model. Redshift can be easily maintained, since no advanced or specialized knowledge is required to do so.\n",
    "\n",
    "#### 5.2 Propose how often the data should be updated and why.\n",
    "\n",
    "For the stated purpose of the model, I beleive the data could be updated weekly given its analytical and non-operational nature.\n",
    "\n",
    "#### 5.3 Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * **The data was increased by 100x.**: I would have preprocessed the data in the cloud since it would be difficult to do it on-premises, a powerful hardware would be required. I've always would have used S3 and Redshift, they can easily adapt to data grow.\n",
    " * **The data populates a dashboard that must be updated on a daily basis by 7am every day.**: \n",
    "  I would have used a tool like Apache Airflow to schedule and run the data pipelines. \n",
    " * **The database needed to be accessed by 100+ people.**: In Redshift Cluster, Node type and the number of nodes can be adjusted as needed to handle the demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
